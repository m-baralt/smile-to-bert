{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8213ff6-c604-40ba-ba82-1d607bd24868",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648c407-55b9-4bd5-9085-1d5ff7e6872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"data/all4M_data.csv\")\n",
    "\n",
    "first_col = data.iloc[:, 0]\n",
    "numeric_data = data.iloc[:, 1:]\n",
    "\n",
    "Q1 = numeric_data.quantile(0.25)\n",
    "Q3 = numeric_data.quantile(0.75)\n",
    "\n",
    "# Remove columns where Q1 and Q3 are the same\n",
    "numeric_data = numeric_data.loc[:, Q1 != Q3]\n",
    "\n",
    "out_of_range = (numeric_data < -1e6) | (numeric_data > 1e6)\n",
    "out_of_range_proportion = out_of_range.mean()\n",
    "threshold = 0.5  \n",
    "columns_to_keep = out_of_range_proportion[out_of_range_proportion <= threshold].index\n",
    "numeric_data = numeric_data[columns_to_keep]\n",
    "numeric_data = numeric_data[(numeric_data >= -1e6) & (numeric_data <= 1e6)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa8656-2246-4ad0-b7d9-458c8bccabef",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_columns = numeric_data.sample(n=15, axis=1, random_state=42)\n",
    "describe_transposed = random_columns.describe().T\n",
    "describe_transposed.to_csv('results/random_columns_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9521e206-3f27-40a0-814e-2278f30d0628",
   "metadata": {},
   "source": [
    "### TDC Datasets prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb5628-1ccf-4393-ac1f-738f791f7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# path with TDC results - obtained with smile-to-bert-tdc\n",
    "directory = \"results_paper/\"\n",
    "json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
    "\n",
    "data = {}\n",
    "for i in range(len(json_files)):\n",
    "    filename = f\"results_paper/{json_files[i]}\"\n",
    "    with open(filename, \"r\") as file:\n",
    "        json_data = json.load(file)\n",
    "        list_names = json_files[i].replace('.json', '').split('_')\n",
    "        if len(list_names)==3:\n",
    "            column_name = f\"{list_names[0]} with {list_names[1]} -- {list_names[2]}\"\n",
    "        elif len(list_names)==2:\n",
    "            column_name = f\"{list_names[1]} with {list_names[0]} -- 256\"\n",
    "        else:\n",
    "            column_name = f\"Combined {list_names[0]} and Smile-to-Bert with {list_names[2]} -- {list_names[3]}\"\n",
    "        data[column_name] = json_data\n",
    "\n",
    "df_total = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49ed6b-f186-497b-87a1-dcaac146bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc.metadata import admet_metrics\n",
    "from tdc.single_pred import ADME\n",
    "from tdc import utils\n",
    "import pandas as pd\n",
    "from tdc.benchmark_group import admet_group\n",
    "\n",
    "adme_datasets = utils.retrieve_benchmark_names('ADMET_Group')\n",
    "\n",
    "\n",
    "adme_info_dict = {}\n",
    "\n",
    "for dataset_name in adme_datasets:\n",
    "    metric = admet_metrics[dataset_name]\n",
    "\n",
    "    if metric in {\"mae\", \"spearman\"}:\n",
    "        task = \"regression\"\n",
    "    else:\n",
    "        task = \"classification\"\n",
    "\n",
    "    group = admet_group(path = 'admet/')\n",
    "    benchmark = group.get(dataset_name) \n",
    "    train, test = benchmark['train_val'], benchmark['test']\n",
    "    total_data = pd.concat([train, test])\n",
    "    \n",
    "    adme_info_dict[dataset_name] = [task,len(total_data),metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe517f-c25c-4cba-9c0b-25ce5fdcc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_adme_info = pd.DataFrame.from_dict(adme_info_dict, orient=\"index\")\n",
    "df_adme_info.columns = ['Task', 'Sample size', 'Metric']\n",
    "df_final = df_adme_info.merge(df_total, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "list_idxs = [0,1,2]\n",
    "for i in range(len(df_final)):\n",
    "    row = df_final.iloc[i, :]\n",
    "    results = row[3:] \n",
    "    values = np.array([val[0] for val in results])\n",
    "    if row['Metric']=='mae':\n",
    "        best_result = values.min()\n",
    "    else:\n",
    "        best_result = values.max()\n",
    "    best_idx = np.where(values == best_result)[0][0]\n",
    "    list_idxs.append(best_idx+3)\n",
    "\n",
    "unique_values = list(set(list_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169ecc1-af84-4c68-9735-157881dc29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = df_final.iloc[:,unique_values]\n",
    "for i in range(len(df_best)):\n",
    "    for j in range(3,len(df_best.columns)):\n",
    "        df_best.iloc[i,j] = f\"{df_best.iloc[i,j][0]:.3f} ({df_best.iloc[i,j][1]:.3f})\"\n",
    "\n",
    "df_best.to_csv('results/tdc_results.csv')\n",
    "df_final.to_csv('results/alltdc_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tdc_env)",
   "language": "python",
   "name": "tdc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
